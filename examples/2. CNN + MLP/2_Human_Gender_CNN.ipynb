{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nguyen Hai Duong\n",
    "# nhduong_3010@live.com\n",
    "# Chonnam National University\n",
    "# 2018.01.21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10   # 10 classes: 0, 1,..., 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 28, 28)\n",
    "x_test = x_test.reshape(10000, 28, 28)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Declare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc3_10ways_softmax (Dense)   (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 28x28 MNIST image\n",
    "input_image = Input(shape=(28, 28), name='Input')\n",
    "\n",
    "# matrix ---> vector\n",
    "x = Flatten(name='flatten')(input_image)\n",
    "\n",
    "# FC layers + dropout\n",
    "x = Dense(units=512, activation='relu', name='fc1')(x)\n",
    "x = Dropout(rate=0.2, name='dropout1')(x)\n",
    "\n",
    "x = Dense(units=512, activation='relu', name='fc2')(x)\n",
    "x = Dropout(rate=0.2, name='dropout2')(x)\n",
    "\n",
    "output_label = Dense(units=num_classes, activation='softmax', name='fc3_10ways_softmax')(x)\n",
    "\n",
    "# define model\n",
    "model = Model(inputs=input_image, outputs=output_label, name='mnist_mlp')\n",
    "\n",
    "# print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) Train defined model\n",
    "- Note that the training history including loss and accuracy will be save in 'history' variable\n",
    "- In case your system runs out of memory (OOM), try to decrease batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 1.2237 - acc: 0.6756 - val_loss: 0.5462 - val_acc: 0.8630\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.5363 - acc: 0.8468 - val_loss: 0.3791 - val_acc: 0.8965\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.4318 - acc: 0.8745 - val_loss: 0.3262 - val_acc: 0.9072\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.3814 - acc: 0.8895 - val_loss: 0.2971 - val_acc: 0.9147\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.3462 - acc: 0.9001 - val_loss: 0.2764 - val_acc: 0.9204\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.3233 - acc: 0.9061 - val_loss: 0.2590 - val_acc: 0.9244\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.3013 - acc: 0.9122 - val_loss: 0.2439 - val_acc: 0.9295\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2859 - acc: 0.9181 - val_loss: 0.2312 - val_acc: 0.9327\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2721 - acc: 0.9217 - val_loss: 0.2207 - val_acc: 0.9361\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2608 - acc: 0.9247 - val_loss: 0.2109 - val_acc: 0.9389\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2469 - acc: 0.9290 - val_loss: 0.2008 - val_acc: 0.9409\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2363 - acc: 0.9320 - val_loss: 0.1924 - val_acc: 0.9435\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2244 - acc: 0.9361 - val_loss: 0.1850 - val_acc: 0.9457\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2159 - acc: 0.9374 - val_loss: 0.1792 - val_acc: 0.9484\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.2090 - acc: 0.9400 - val_loss: 0.1727 - val_acc: 0.9495\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2008 - acc: 0.9417 - val_loss: 0.1662 - val_acc: 0.9514\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1960 - acc: 0.9431 - val_loss: 0.1605 - val_acc: 0.9528\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1886 - acc: 0.9457 - val_loss: 0.1561 - val_acc: 0.9538\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1821 - acc: 0.9471 - val_loss: 0.1512 - val_acc: 0.9557\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1772 - acc: 0.9489 - val_loss: 0.1468 - val_acc: 0.9568\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1711 - acc: 0.9501 - val_loss: 0.1426 - val_acc: 0.9576\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1668 - acc: 0.9515 - val_loss: 0.1388 - val_acc: 0.9602\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.1631 - acc: 0.9527 - val_loss: 0.1357 - val_acc: 0.9605\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1571 - acc: 0.9549 - val_loss: 0.1332 - val_acc: 0.9614\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1542 - acc: 0.9554 - val_loss: 0.1302 - val_acc: 0.9620\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1502 - acc: 0.9568 - val_loss: 0.1271 - val_acc: 0.9631\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1474 - acc: 0.9578 - val_loss: 0.1242 - val_acc: 0.9639\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.1432 - acc: 0.9580 - val_loss: 0.1211 - val_acc: 0.9647\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1390 - acc: 0.9588 - val_loss: 0.1188 - val_acc: 0.9651\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1351 - acc: 0.9607 - val_loss: 0.1174 - val_acc: 0.9655\n",
      "> training time is 1.4402 minutes\n"
     ]
    }
   ],
   "source": [
    "# declare learning rate, loss function, and model metric\n",
    "loss = 'categorical_crossentropy'\n",
    "lr = 0.01\n",
    "model.compile(loss=loss, optimizer=SGD(lr=lr), metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "\n",
    "starting_time = time.time()\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs)\n",
    "print('> training time is %.4f minutes' % ((time.time() - starting_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training time\n",
    "- Training time with GTX 1080 is about 1.4402 minutes for 30 epoches\n",
    "- Training time with Core i7 is around 3.0493 minutes for 30 epoches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) Evaluate trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 61us/step\n",
      "Test loss: 0.11284465673938393\n",
      "Test accuracy: 0.9657\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e003c51128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select a test image randomly\n",
    "random_test_index = np.random.choice(x_test.shape[0], size=1)[0]\n",
    "test_img = x_test[random_test_index]\n",
    "test_label = np.argmax(y_test[random_test_index])\n",
    "\n",
    "# predict test image with trained model\n",
    "pred_label = model.predict(np.expand_dims(test_img, axis=0))\n",
    "pred_label = np.argmax(pred_label)\n",
    "\n",
    "plt.imshow(test_img, cmap='gray')\n",
    "plt.title('true label = %d, predicted label = %d' % (test_label, pred_label))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
